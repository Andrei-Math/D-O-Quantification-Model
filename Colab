{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_code_claims.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOekdDlR8x366qGJYMyidhO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrei-Math/ABN/blob/master/ANN_code_claims.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgrKHgHm5Wp3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: correct the way to make Xtrain with correct index and remove NAs\n",
        "Xtrain = pd.read_csv(\"Xtrain.csv\", index_col=0)\n",
        "Xtest = pd.read_csv(\"Xtest.csv\", index_col=0)\n",
        "ytrain = pd.read_csv(\"ytrain.csv\", index_col=0).rename(columns={'V1':'ClaimNb'})\n",
        "ytest = pd.read_csv(\"ytest.csv\", index_col=0).rename(columns={'V1':'ClaimNb'})\n",
        "\n",
        "# store predictions for each model\n",
        "train = pd.DataFrame()\n",
        "test = pd.DataFrame()\n",
        "train['ClaimNb'] = ytrain['ClaimNb']\n",
        "test['ClaimNb'] = ytest['ClaimNb']\n",
        "\n",
        "# store results for each model\n",
        "train_results = pd.DataFrame(index=['poisson deviance'])\n",
        "test_results = pd.DataFrame(index=['poisson deviance'])\n",
        "\n",
        "display(Xtrain.head())\n",
        "print(Xtrain.shape)\n",
        "display(ytrain.head())\n",
        "print('NA in Xtrain = ', (pd.isna(Xtrain)).sum().sum())\n",
        "print(ytrain.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "8SNh2QYBApiD",
        "outputId": "27084c7c-5a44-462c-d503-c070650673c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   REVENUESX  is_USA_jurisX   R2   R3   R4   R5   R6   R7   R8   R9  ...  S3  \\\n",
              "2  -0.959481            0.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   \n",
              "3  -0.959481            0.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0   \n",
              "6  -0.959481            0.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   0   \n",
              "7  -0.741298            0.5  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0   \n",
              "8  -0.415797            0.5  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0   \n",
              "\n",
              "   S4  S5  S6  S7  S8  S9  S10  S11  S12  \n",
              "2   0   0   0   1   0   0    0    0    0  \n",
              "3   0   0   0   0   1   0    0    0    0  \n",
              "6   1   0   0   0   0   0    0    0    0  \n",
              "7   1   0   0   0   0   0    0    0    0  \n",
              "8   1   0   0   0   0   0    0    0    0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc9dd64c-e262-4309-89c8-8de14fd61c38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>REVENUESX</th>\n",
              "      <th>is_USA_jurisX</th>\n",
              "      <th>R2</th>\n",
              "      <th>R3</th>\n",
              "      <th>R4</th>\n",
              "      <th>R5</th>\n",
              "      <th>R6</th>\n",
              "      <th>R7</th>\n",
              "      <th>R8</th>\n",
              "      <th>R9</th>\n",
              "      <th>...</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>S5</th>\n",
              "      <th>S6</th>\n",
              "      <th>S7</th>\n",
              "      <th>S8</th>\n",
              "      <th>S9</th>\n",
              "      <th>S10</th>\n",
              "      <th>S11</th>\n",
              "      <th>S12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.959481</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.959481</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.959481</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.741298</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.415797</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc9dd64c-e262-4309-89c8-8de14fd61c38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc9dd64c-e262-4309-89c8-8de14fd61c38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc9dd64c-e262-4309-89c8-8de14fd61c38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6498, 30)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   ClaimNb\n",
              "1        1\n",
              "2        1\n",
              "3        1\n",
              "4        1\n",
              "5        1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e8d0b55-3767-4eaf-8742-027c4f9b864c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ClaimNb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e8d0b55-3767-4eaf-8742-027c4f9b864c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e8d0b55-3767-4eaf-8742-027c4f9b864c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e8d0b55-3767-4eaf-8742-027c4f9b864c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NA in Xtrain =  544\n",
            "(6498, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xtrain.columns[Xtrain.nunique() <= 1]\n",
        "# Xtest.columns[Xtest.nunique() <= 1]\n",
        "# if 'R18' in Xtrain:\n",
        "#   Xtrain = Xtrain.drop(columns=['R18'])\n",
        "# for col in Xtrain:\n",
        "#   Xtrain[col] = Xtrain[col].astype('float64')\n",
        "Xtrain = Xtrain.dropna()\n",
        "Xtrain.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "csv8UPl3h573",
        "outputId": "3914b0b3-0738-4b2c-fde6-7e68ee755fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      REVENUESX  is_USA_jurisX   R2   R3   R4   R5   R6   R7   R8   R9  ...  \\\n",
              "8113  -0.959481           -0.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
              "8114  -0.959398           -0.5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \n",
              "8115  -0.959351           -0.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
              "8118  -0.957361            0.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
              "8119  -0.959481            0.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   \n",
              "\n",
              "      S3  S4  S5  S6  S7  S8  S9  S10  S11  S12  \n",
              "8113   0   1   0   0   0   0   0    0    0    0  \n",
              "8114   0   1   0   0   0   0   0    0    0    0  \n",
              "8115   0   1   0   0   0   0   0    0    0    0  \n",
              "8118   0   1   0   0   0   0   0    0    0    0  \n",
              "8119   0   1   0   0   0   0   0    0    0    0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cf1acc5-1ccb-42d5-a458-0c26f81f52de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>REVENUESX</th>\n",
              "      <th>is_USA_jurisX</th>\n",
              "      <th>R2</th>\n",
              "      <th>R3</th>\n",
              "      <th>R4</th>\n",
              "      <th>R5</th>\n",
              "      <th>R6</th>\n",
              "      <th>R7</th>\n",
              "      <th>R8</th>\n",
              "      <th>R9</th>\n",
              "      <th>...</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>S5</th>\n",
              "      <th>S6</th>\n",
              "      <th>S7</th>\n",
              "      <th>S8</th>\n",
              "      <th>S9</th>\n",
              "      <th>S10</th>\n",
              "      <th>S11</th>\n",
              "      <th>S12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8113</th>\n",
              "      <td>-0.959481</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8114</th>\n",
              "      <td>-0.959398</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8115</th>\n",
              "      <td>-0.959351</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8118</th>\n",
              "      <td>-0.957361</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8119</th>\n",
              "      <td>-0.959481</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cf1acc5-1ccb-42d5-a458-0c26f81f52de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cf1acc5-1ccb-42d5-a458-0c26f81f52de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cf1acc5-1ccb-42d5-a458-0c26f81f52de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = ytrain.loc[Xtrain.index,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "ONsFNjrkjvTs",
        "outputId": "ecaf9796-3e8f-4c7e-9e9f-4987251bbb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1c3dc574aaf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[6499, 6500, 6501, 6502, 6505, 6506, 6507, 6508, 6509, 6510, 6511, 6512, 6513, 6517, 6518, 6519, 6520, 6521, 6522, 6523, 6524, 6525, 6526, 6527, 6528, 6529, 6531, 6532, 6533, 6534, 6535, 6536, 6537, 6539, 6540, 6541, 6542, 6545, 6546, 6548, 6549, 6550, 6551, 6552, 6553, 6554, 6555, 6556, 6557, 6558, 6561, 6562, 6563, 6564, 6565, 6566, 6568, 6570, 6571, 6572, 6573, 6574, 6575, 6576, 6577, 6578, 6579, 6580, 6583, 6584, 6585, 6586, 6587, 6588, 6589, 6590, 6592, 6595, 6597, 6598, 6599, 6600, 6601, 6602, 6603, 6604, 6606, 6607, 6608, 6609, 6610, 6611, 6612, 6614, 6615, 6616, 6619, 6620, 6621, 6622, 6623, 6624, 6625, 6626, 6627, 6628, 6629, 6630, 6631, 6632, 6634, 6635, 6636, 6637, 6639, 6640, 6641, 6642, 6643, 6644, 6647, 6648, 6650, 6652, 6653, 6654, 6655, 6656, 6657, 6658, 6659, 6660, 6661, 6662, 6663, 6664, 6667, 6668, 6669, 6670, 6671, 6672, 6674, 6675, 6676, 6678, 6681, 6682, 6683, 6684, 6685, 6686, 6687, 6689, 6692, 6693, 6695, 6696, 6697, 6698, 6699, 6700, 6701, 6704, 6705, 6706, 6707, 6708, 6709, 6710, 6711, 6712, 6714, 6715, 6716, 6717, 6718, 6719, 6720, 6721, 6722, 6723, 6724, 6725, 6726, 6727, 6728, 6729, 6730, 6732, 6734, 6735, 6736, 6737, 6738, 6739, 6740, 6742, 6745, 6747, 6750, 6751, 6752, 6753, 6755, 6756, 6757, 6758, 6759, 6760, 6761, 6762, 6763, 6764, 6765, 6766, 6767, 6768, 6771, 6772, 6773, 6774, 6776, 6778, 6779, 6780, 6781, 6782, 6783, 6785, 6786, 6787, 6788, 6790, 6791, 6793, 6794, 6796, 6797, 6798, 6799, 6800, 6802, 6803, 6805, 6806..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LejN86zOjCkL",
        "outputId": "803f3f88-c7c5-4fe9-9a4e-48b139bf2dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6498 entries, 2 to 8119\n",
            "Data columns (total 29 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   REVENUESX      6498 non-null   float64\n",
            " 1   is_USA_jurisX  6498 non-null   float64\n",
            " 2   R2             6466 non-null   float64\n",
            " 3   R3             6466 non-null   float64\n",
            " 4   R4             6466 non-null   float64\n",
            " 5   R5             6466 non-null   float64\n",
            " 6   R6             6466 non-null   float64\n",
            " 7   R7             6466 non-null   float64\n",
            " 8   R8             6466 non-null   float64\n",
            " 9   R9             6466 non-null   float64\n",
            " 10  R10            6466 non-null   float64\n",
            " 11  R11            6466 non-null   float64\n",
            " 12  R12            6466 non-null   float64\n",
            " 13  R13            6466 non-null   float64\n",
            " 14  R14            6466 non-null   float64\n",
            " 15  R15            6466 non-null   float64\n",
            " 16  R16            6466 non-null   float64\n",
            " 17  R17            6466 non-null   float64\n",
            " 18  S2             6498 non-null   float64\n",
            " 19  S3             6498 non-null   float64\n",
            " 20  S4             6498 non-null   float64\n",
            " 21  S5             6498 non-null   float64\n",
            " 22  S6             6498 non-null   float64\n",
            " 23  S7             6498 non-null   float64\n",
            " 24  S8             6498 non-null   float64\n",
            " 25  S9             6498 non-null   float64\n",
            " 26  S10            6498 non-null   float64\n",
            " 27  S11            6498 non-null   float64\n",
            " 28  S12            6498 non-null   float64\n",
            "dtypes: float64(29)\n",
            "memory usage: 1.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pointbiserialr\n",
        "print('Correlation betwen Revenue and claim count = ', np.corrcoef(Xtrain['REVENUESX'], ytrain['ClaimNb'])[0,1])\n",
        "#print('Correlation betwen Employees and claim count = ', np.corrcoef(Xtrain['EMPLOYEESX'], ytrain['ClaimNb'])[0,1])\n",
        "print('Correlation betwen USA juris and claim count = ', pointbiserialr(Xtrain['is_USA_jurisX'], ytrain['ClaimNb']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL5g2JZXO1wA",
        "outputId": "a7659123-7ec1-424a-c3a1-476ccc8cc86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation betwen Revenue and claim count =  0.11602294202052407\n",
            "Correlation betwen USA juris and claim count =  PointbiserialrResult(correlation=0.05435534285129983, pvalue=1.1652426198402238e-05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q0 = Xtrain.shape[1] # number of input features\n",
        "q1 = 100  # number of neurons in hidden layer"
      ],
      "metadata": {
        "id": "RwqZcUncCkZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_hom = sum(ytrain['ClaimNb'])/len(ytrain)\n",
        "lambda_hom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m0jYoldGLge",
        "outputId": "cae19f42-1898-403b-e1f2-c9906b761907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3054786088027086"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(q1, input_shape=(q0,), activation='tanh'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='linear', kernel_initializer=tf.keras.initializers.Constant(tf.math.log(lambda_hom)), bias_initializer=tf.keras.initializers.Zeros()))\n",
        "model.add(tf.keras.layers.Dense(1, activation='exponential', trainable=False, kernel_initializer=tf.keras.initializers.Ones(),\n",
        "    bias_initializer=tf.keras.initializers.Zeros()))"
      ],
      "metadata": {
        "id": "05IKtIOsB3Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='poisson', optimizer='nadam', metrics=['mse'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xSlulxzDyqC",
        "outputId": "b67dbf9a-21db-47a2-ffce-46488badd1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               3000      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103\n",
            "Trainable params: 3,101\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "batch_size = 1000\n",
        "validation_split = 0.2  # set to >0 to see train/validation loss in plot(fit)\n",
        "verbose = 1"
      ],
      "metadata": {
        "id": "9vI2jut2FQli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(Xtrain, ytrain['ClaimNb'], epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=verbose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iZ821WV7Ht6e",
        "outputId": "5a62e878-7d77-4830-ce69-d82d398880dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 44ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 242/300\n",
            "1/6 [====>.........................] - ETA: 0s - loss: nan - mse: nan"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-179b2ce506ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ClaimNb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 755\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3316\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3BMbE3o6ILsI",
        "outputId": "6e4bd567-47b1-4ea8-bd65-24356c7b7687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f07bae1dd10>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PoissonDeviance = tf.keras.metrics.poisson\n",
        "\n",
        "train['shNN'] = model.predict(Xtrain)\n",
        "test['shNN'] = model.predict(Xtest)\n",
        "\n",
        "in_sample_loss = PoissonDeviance(train['ClaimNb'], train['shNN'])\n",
        "out_sample_loss = PoissonDeviance(test['ClaimNb'], test['shNN'])\n",
        "print(f\"Poisson deviance shallow network (train): {in_sample_loss.numpy() :.3f}\" )\n",
        "print(f\"Poisson deviance shallow network (test): {out_sample_loss.numpy() :.3f}\" )\n",
        "\n",
        "train_results['shNN'] = [in_sample_loss]\n",
        "test_results['shNN'] = [out_sample_loss]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_snj-yJInKS",
        "outputId": "9f38e2e1-d3bd-4554-c0e1-381724902557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisson deviance shallow network (train): nan\n",
            "Poisson deviance shallow network (test): nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shNN_frequency = sum(test['shNN']) / len(test)\n",
        "print(f\"Average frequency (test): {shNN_frequency: .3f}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thWyL7V-KY3f",
        "outputId": "17ec3181-583c-4aff-c4b4-6e79778256c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average frequency (test):  nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_df = Xtest.copy()\n",
        "plot_df['ClaimNb'] = test['ClaimNb']\n",
        "plot_df['shNN'] = test['shNN']\n",
        "\n",
        "grouped_data = plot_df.groupby(by=['is_USA_jurisX']).mean()\n",
        "ax = grouped_data.plot(y='ClaimNb', marker='o')\n",
        "grouped_data.plot(y='shNN', marker='x', ax=ax);\n",
        "\n",
        "grouped_data = plot_df.groupby(by=['R2','R3']).mean()\n",
        "ax2 = grouped_data.plot(y='ClaimNb', marker='o')\n",
        "grouped_data.plot(y='shNN', marker='x', ax=ax2);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "zUAlHxIyRZSN",
        "outputId": "0b53be4d-c525-42f6-b0cf-e47baaf68d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep vanillha neural network"
      ],
      "metadata": {
        "id": "y0OPO7e8lQu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define network\n",
        "q0 = Xtrain.shape[1]   # dimension of features\n",
        "q1 = 20                 # number of neurons in first hidden layer\n",
        "q2 = 15                 # number of neurons in second hidden layer\n",
        "q3 = 10                 # number of neurons in second hidden layer\n",
        "\n",
        "print(\"Neural network with K=3 hidden layer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HanG5xdATkOO",
        "outputId": "735f5786-3b10-47f5-dafa-ba2a61aed6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network with K=3 hidden layer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential()\n",
        "model2.add(tf.keras.layers.Dense(q1, input_shape=(q0,), activation='tanh'))\n",
        "model2.add(tf.keras.layers.Dense(q2, activation='tanh'))\n",
        "model2.add(tf.keras.layers.Dense(q3, activation='tanh'))\n",
        "model2.add(tf.keras.layers.Dense(1, activation='linear', kernel_initializer=tf.keras.initializers.Constant(tf.math.log(lambda_hom)), bias_initializer=tf.keras.initializers.Zeros()))\n",
        "model2.add(tf.keras.layers.Dense(1, activation='exponential', trainable=False, kernel_initializer=tf.keras.initializers.Ones(),\n",
        "    bias_initializer=tf.keras.initializers.Zeros()))"
      ],
      "metadata": {
        "id": "81zq2sfkl36D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='poisson', optimizer='nadam', metrics=['mse'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9c6f0c-0979-4c11-b4e6-bf5ff1fa0a15",
        "id": "afQ9sdRRl36D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 20)                620       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 15)                315       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                160       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,108\n",
            "Trainable params: 1,106\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "batch_size = 1000\n",
        "validation_split = 0.2  # set to >0 to see train/validation loss in plot(fit)\n",
        "verbose = 1"
      ],
      "metadata": {
        "id": "Zd4lxFH6l36E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(Xtrain, ytrain['ClaimNb'], epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=verbose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "635820c5-bee7-43f6-de55-86d956d42d84",
        "id": "mAk-Qgv4l36F"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 40ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
            "Epoch 83/300\n",
            "1/6 [====>.........................] - ETA: 0s - loss: nan - mse: nan"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-989096e0b8fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ClaimNb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 755\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3316\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "nw3iBipdl36F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PoissonDeviance = tf.keras.metrics.poisson\n",
        "\n",
        "train['dpNN'] = model2.predict(Xtrain)\n",
        "test['dpNN'] = model2.predict(Xtest)\n",
        "\n",
        "in_sample_loss = PoissonDeviance(train['ClaimNb'], train['dpNN'])\n",
        "out_sample_loss = PoissonDeviance(test['ClaimNb'], test['dpNN'])\n",
        "print(f\"Poisson deviance shallow network (train): {in_sample_loss.numpy() :.3f}\" )\n",
        "print(f\"Poisson deviance shallow network (test): {out_sample_loss.numpy() :.3f}\" )\n",
        "\n",
        "train_results['dpNN'] = [in_sample_loss]\n",
        "test_results['dpNN'] = [out_sample_loss]"
      ],
      "metadata": {
        "id": "TcawO5Yml36F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dpNN_frequency = sum(test['dpNN']) / len(test)\n",
        "print(f\"Average frequency (test): {dpNN_frequency: .3f}\" )"
      ],
      "metadata": {
        "id": "Q8dq_OG0l36F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Deep neural network with dropout layers"
      ],
      "metadata": {
        "id": "6Ku5pJkbRrY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q0 = Xtrain.shape[1]   # dimension of features\n",
        "q1 = 20                 # number of neurons in first hidden layer\n",
        "q2 = 15                 # number of neurons in second hidden layer\n",
        "q3 = 10                 # number of neurons in second hidden layer\n",
        "p0 = 0.05               # dropout rate     "
      ],
      "metadata": {
        "id": "NX2Yxsd3n38q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tf.keras.Sequential()\n",
        "model3.add(tf.keras.layers.Dense(q1, input_shape=(q0,), activation='tanh'))\n",
        "model3.add(tf.keras.layers.Dropout(p0))\n",
        "model3.add(tf.keras.layers.Dense(q2, activation='tanh'))\n",
        "model3.add(tf.keras.layers.Dropout(p0))\n",
        "model3.add(tf.keras.layers.Dense(q3, activation='tanh'))\n",
        "model3.add(tf.keras.layers.Dropout(p0))\n",
        "model3.add(tf.keras.layers.Dense(1, activation='linear', kernel_initializer=tf.keras.initializers.Constant(tf.math.log(lambda_hom)), bias_initializer=tf.keras.initializers.Zeros()))\n",
        "model3.add(tf.keras.layers.Dense(1, activation='exponential', trainable=False, kernel_initializer=tf.keras.initializers.Ones(),\n",
        "    bias_initializer=tf.keras.initializers.Zeros()))"
      ],
      "metadata": {
        "id": "PV90cMAzUDiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss='poisson', optimizer='nadam', metrics=['mse'])\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "ZQaicqgLUDiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "batch_size = 1000\n",
        "validation_split = 0.2  # set to >0 to see train/validation loss in plot(fit)\n",
        "verbose = 1"
      ],
      "metadata": {
        "id": "6utKOUvDUDiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(Xtrain, ytrain['ClaimNb'], epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=verbose)"
      ],
      "metadata": {
        "id": "yStJKzXGUDiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "metadata": {
        "id": "3O32MGhrUDiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PoissonDeviance = tf.keras.metrics.poisson\n",
        "\n",
        "train['drNN'] = model3.predict(Xtrain)\n",
        "test['drNN'] = model3.predict(Xtest)\n",
        "\n",
        "in_sample_loss = PoissonDeviance(train['ClaimNb'], train['drNN'])\n",
        "out_sample_loss = PoissonDeviance(test['ClaimNb'], test['drNN'])\n",
        "print(f\"Poisson deviance shallow network (train): {in_sample_loss.numpy() :.3f}\" )\n",
        "print(f\"Poisson deviance shallow network (test): {out_sample_loss.numpy() :.3f}\" )\n",
        "\n",
        "train_results['drNN'] = [in_sample_loss]\n",
        "test_results['drNN'] = [out_sample_loss]"
      ],
      "metadata": {
        "id": "cl0YySyoUDiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drNN_frequency = sum(test['drNN']) / len(test)\n",
        "print(f\"Average frequency (test): {drNN_frequency: .3f}\" )"
      ],
      "metadata": {
        "id": "ut8q9W1_UX9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOdel comparison\n"
      ],
      "metadata": {
        "id": "WkwInFdFVl4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In sample performance\n",
        "pd.DataFrame(train_results)"
      ],
      "metadata": {
        "id": "bdUo1jvkVuZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Out of sample performance\n",
        "pd.DataFrame(test_results)"
      ],
      "metadata": {
        "id": "etJ23HPgVu-4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
